#!/usr/bin/env python3
"""
Support AI System - Main Entry Point
=====================================
Self-Learning Support Knowledge Engine

A fault-tolerant, resumable, self-learning AI knowledge platform
using local LLMs for enterprise customer support.

Usage:
    python main.py --init       Initialize the system
    python main.py --baseline   Run baseline evaluation
    python main.py --train      Start training pipeline
    python main.py --resume     Resume from checkpoint
    python main.py --evaluate   Run full evaluation
    python main.py --serve      Start the system server

Author: SupportMind AI Team
Version: 1.0.0
"""

import os
import sys
import click
import logging
import asyncio
from pathlib import Path
from datetime import datetime

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from src.orchestration.orchestrator import SystemOrchestrator
from src.orchestration.progress_tracker import ProgressTracker
from src.utils.config import load_config
from src.utils.logger import setup_logging
from src.utils.directory_setup import ensure_directories


# =============================================================================
# CLI COMMANDS
# =============================================================================

@click.group()
@click.option('--config', '-c', default='config.yaml', help='Configuration file path')
@click.option('--verbose', '-v', is_flag=True, help='Enable verbose output')
@click.pass_context
def cli(ctx, config: str, verbose: bool):
    """
    SupportMind AI - Self-Learning Support Knowledge Engine
    
    Enterprise-grade AI system for customer support intelligence.
    """
    ctx.ensure_object(dict)
    
    # Load configuration
    ctx.obj['config'] = load_config(config)
    ctx.obj['verbose'] = verbose
    
    # Setup logging
    log_level = 'DEBUG' if verbose else ctx.obj['config']['system']['log_level']
    setup_logging(ctx.obj['config'], log_level)
    
    # Ensure directory structure
    ensure_directories(ctx.obj['config'])


@cli.command()
@click.pass_context
def init(ctx):
    """Initialize the system - creates database, indexes, and required structures."""
    config = ctx.obj['config']
    
    click.echo("=" * 60)
    click.echo("üöÄ INITIALIZING SUPPORTMIND AI SYSTEM")
    click.echo("=" * 60)
    
    orchestrator = SystemOrchestrator(config)
    
    try:
        # Initialize all components
        click.echo("\nüìÅ Creating directory structure...")
        ensure_directories(config)
        
        click.echo("üóÑÔ∏è  Initializing database...")
        orchestrator.init_database()
        
        click.echo("üìä Loading Excel data...")
        orchestrator.ingest_data()
        
        click.echo("üîç Building embedding indexes...")
        orchestrator.build_indexes()
        
        click.echo("üìù Setting up prompt templates...")
        orchestrator.init_prompts()
        
        click.echo("\n" + "=" * 60)
        click.echo("‚úÖ INITIALIZATION COMPLETE")
        click.echo("=" * 60)
        click.echo("\nNext steps:")
        click.echo("  1. Run baseline: python main.py baseline")
        click.echo("  2. Start training: python main.py train")
        
    except Exception as e:
        logging.error(f"Initialization failed: {e}")
        click.echo(f"\n‚ùå Initialization failed: {e}")
        sys.exit(1)


@cli.command()
@click.pass_context
def baseline(ctx):
    """Run baseline evaluation without training."""
    config = ctx.obj['config']
    
    click.echo("=" * 60)
    click.echo("üìä RUNNING BASELINE EVALUATION")
    click.echo("=" * 60)
    
    orchestrator = SystemOrchestrator(config)
    progress = ProgressTracker(config)
    
    try:
        orchestrator.load_state()
        
        click.echo("\nüîç Evaluating retrieval performance...")
        retrieval_metrics = orchestrator.evaluate_retrieval()
        
        click.echo("üìù Evaluating KB quality...")
        quality_metrics = orchestrator.evaluate_kb_quality()
        
        click.echo("‚úÖ Computing QA scores...")
        qa_metrics = orchestrator.evaluate_qa()
        
        # Display results
        click.echo("\n" + "=" * 60)
        click.echo("üìà BASELINE RESULTS")
        click.echo("=" * 60)
        
        click.echo(f"\nRetrieval Metrics:")
        click.echo(f"  Hit@1:  {retrieval_metrics.get('hit_at_1', 0):.3f}")
        click.echo(f"  Hit@3:  {retrieval_metrics.get('hit_at_3', 0):.3f}")
        click.echo(f"  MRR:    {retrieval_metrics.get('mrr', 0):.3f}")
        
        click.echo(f"\nKB Quality:")
        click.echo(f"  Avg Cosine:     {quality_metrics.get('avg_cosine', 0):.3f}")
        click.echo(f"  Structural:     {quality_metrics.get('structural_score', 0):.3f}")
        click.echo(f"  LLM Judge:      {quality_metrics.get('llm_judge_score', 0):.3f}")
        
        click.echo(f"\nQA Metrics:")
        click.echo(f"  Mean Score:     {qa_metrics.get('mean_score', 0):.3f}")
        click.echo(f"  Violations:     {qa_metrics.get('violations', 0)}")
        
        # Save baseline
        orchestrator.save_baseline_metrics({
            'retrieval': retrieval_metrics,
            'quality': quality_metrics,
            'qa': qa_metrics,
            'timestamp': datetime.now().isoformat()
        })
        
        click.echo("\n‚úÖ Baseline saved to metrics/baseline.json")
        
    except Exception as e:
        logging.error(f"Baseline evaluation failed: {e}")
        click.echo(f"\n‚ùå Baseline failed: {e}")
        sys.exit(1)


@cli.command()
@click.option('--rounds', '-r', default=None, type=int, help='Number of training rounds')
@click.pass_context
def train(ctx, rounds: int):
    """Start the batch training pipeline."""
    config = ctx.obj['config']
    
    if rounds:
        config['learning']['num_rounds'] = rounds
    
    click.echo("=" * 60)
    click.echo("üß† STARTING TRAINING PIPELINE")
    click.echo("=" * 60)
    
    orchestrator = SystemOrchestrator(config)
    progress = ProgressTracker(config)
    
    try:
        orchestrator.load_state()
        
        num_rounds = config['learning']['num_rounds']
        click.echo(f"\nüìö Training for {num_rounds} rounds")
        click.echo(f"   Train ratio: {config['learning']['train_ratio']}")
        click.echo(f"   Buffer size: {config['learning']['buffer_size']}")
        
        # Run training loop
        asyncio.run(orchestrator.run_training_pipeline(
            num_rounds=num_rounds,
            progress_callback=progress.update
        ))
        
        click.echo("\n" + "=" * 60)
        click.echo("‚úÖ TRAINING COMPLETE")
        click.echo("=" * 60)
        
        # Show final metrics
        final_metrics = orchestrator.get_final_metrics()
        progress.print_final_report(final_metrics)
        
    except KeyboardInterrupt:
        click.echo("\n‚ö†Ô∏è  Training interrupted - saving checkpoint...")
        orchestrator.save_checkpoint()
        click.echo("üíæ Checkpoint saved. Resume with: python main.py resume")
        
    except Exception as e:
        logging.error(f"Training failed: {e}")
        orchestrator.save_checkpoint()
        click.echo(f"\n‚ùå Training failed: {e}")
        click.echo("üíæ Checkpoint saved. Resume with: python main.py resume")
        sys.exit(1)


@cli.command()
@click.pass_context
def resume(ctx):
    """Resume training from the last checkpoint."""
    config = ctx.obj['config']
    
    click.echo("=" * 60)
    click.echo("üîÑ RESUMING FROM CHECKPOINT")
    click.echo("=" * 60)
    
    orchestrator = SystemOrchestrator(config)
    progress = ProgressTracker(config)
    
    try:
        # Load checkpoint
        checkpoint = orchestrator.load_checkpoint()
        
        if not checkpoint:
            click.echo("‚ùå No checkpoint found. Run --init first.")
            sys.exit(1)
        
        click.echo(f"\nüìç Resuming from:")
        click.echo(f"   Batch ID:        {checkpoint.get('batch_id', 'N/A')}")
        click.echo(f"   Round:           {checkpoint.get('round', 0) + 1}")
        click.echo(f"   Progress:        {checkpoint.get('progress_pct', 0):.1f}%")
        click.echo(f"   Saved at:        {checkpoint.get('timestamp', 'Unknown')}")
        
        # Resume training
        asyncio.run(orchestrator.resume_training(
            checkpoint=checkpoint,
            progress_callback=progress.update
        ))
        
        click.echo("\n" + "=" * 60)
        click.echo("‚úÖ TRAINING RESUMED AND COMPLETED")
        click.echo("=" * 60)
        
    except Exception as e:
        logging.error(f"Resume failed: {e}")
        orchestrator.save_checkpoint()
        click.echo(f"\n‚ùå Resume failed: {e}")
        sys.exit(1)


@cli.command()
@click.option('--full', is_flag=True, help='Run full evaluation suite')
@click.pass_context
def evaluate(ctx, full: bool):
    """Run comprehensive evaluation."""
    config = ctx.obj['config']
    
    click.echo("=" * 60)
    click.echo("üìä RUNNING EVALUATION")
    click.echo("=" * 60)
    
    orchestrator = SystemOrchestrator(config)
    
    try:
        orchestrator.load_state()
        
        results = orchestrator.run_full_evaluation(full=full)
        
        # Display comprehensive results
        click.echo("\n" + "=" * 60)
        click.echo("üìà EVALUATION RESULTS")
        click.echo("=" * 60)
        
        click.echo("\nüîç RETRIEVAL METRICS")
        click.echo("-" * 40)
        for k, v in results['retrieval'].items():
            click.echo(f"  {k}: {v:.4f}")
        
        click.echo("\nüìù COVERAGE METRICS")
        click.echo("-" * 40)
        click.echo(f"  Questions answered: {results['coverage']['answered']}")
        click.echo(f"  Total questions:    {results['coverage']['total']}")
        click.echo(f"  Coverage rate:      {results['coverage']['rate']:.2%}")
        
        click.echo("\n‚ú® KB QUALITY METRICS")
        click.echo("-" * 40)
        for k, v in results['quality'].items():
            click.echo(f"  {k}: {v:.4f}")
        
        click.echo("\n‚úÖ QA METRICS")
        click.echo("-" * 40)
        click.echo(f"  Mean score:    {results['qa']['mean_score']:.3f}")
        click.echo(f"  Min score:     {results['qa']['min_score']:.3f}")
        click.echo(f"  Max score:     {results['qa']['max_score']:.3f}")
        click.echo(f"  Violations:    {results['qa']['violations']}")
        
        # Save results
        orchestrator.save_evaluation_results(results)
        click.echo("\nüíæ Results saved to metrics/evaluation_results.json")
        
    except Exception as e:
        logging.error(f"Evaluation failed: {e}")
        click.echo(f"\n‚ùå Evaluation failed: {e}")
        sys.exit(1)


@cli.command()
@click.option('--port', '-p', default=8080, help='Server port')
@click.option('--host', '-h', default='0.0.0.0', help='Server host')
@click.pass_context
def serve(ctx, port: int, host: str):
    """Start the system server for API access."""
    config = ctx.obj['config']
    
    click.echo("=" * 60)
    click.echo("üåê STARTING SUPPORTMIND AI SERVER")
    click.echo("=" * 60)
    
    try:
        from src.api.server import create_app
        
        app = create_app(config)
        
        click.echo(f"\nüöÄ Server running at http://{host}:{port}")
        click.echo("   Press Ctrl+C to stop")
        
        import uvicorn
        uvicorn.run(app, host=host, port=port)
        
    except ImportError:
        click.echo("‚ùå Server dependencies not installed.")
        click.echo("   Run: pip install uvicorn fastapi")
        sys.exit(1)
    except Exception as e:
        logging.error(f"Server failed: {e}")
        click.echo(f"\n‚ùå Server failed: {e}")
        sys.exit(1)


@cli.command()
@click.pass_context
def status(ctx):
    """Show current system status."""
    config = ctx.obj['config']
    
    click.echo("=" * 60)
    click.echo("üìä SYSTEM STATUS")
    click.echo("=" * 60)
    
    orchestrator = SystemOrchestrator(config)
    progress = ProgressTracker(config)
    
    try:
        status = orchestrator.get_status()
        
        click.echo(f"\nüîß System:")
        click.echo(f"   Version:      {config['system']['version']}")
        click.echo(f"   Environment:  {config['system']['environment']}")
        
        click.echo(f"\nüóÑÔ∏è  Database:")
        click.echo(f"   Status:       {'‚úÖ Connected' if status['db_connected'] else '‚ùå Disconnected'}")
        click.echo(f"   Tables:       {status['table_count']}")
        click.echo(f"   Records:      {status['total_records']}")
        
        click.echo(f"\nüîç Indexes:")
        click.echo(f"   FAISS:        {'‚úÖ Built' if status['faiss_ready'] else '‚ùå Not built'}")
        click.echo(f"   BM25:         {'‚úÖ Built' if status['bm25_ready'] else '‚ùå Not built'}")
        
        click.echo(f"\nüß† LLM:")
        click.echo(f"   Provider:     {config['llm']['provider']}")
        click.echo(f"   Model:        {config['llm']['ollama']['model']}")
        click.echo(f"   Status:       {'‚úÖ Available' if status['llm_available'] else '‚ùå Unavailable'}")
        
        click.echo(f"\nüìà Progress:")
        click.echo(f"   Dataset:      {status['progress']['dataset_pct']:.1f}%")
        click.echo(f"   KB Coverage:  {status['progress']['kb_coverage_pct']:.1f}%")
        click.echo(f"   Phase:        {status['progress']['current_phase']}")
        
        if status.get('checkpoint'):
            click.echo(f"\nüíæ Last Checkpoint:")
            click.echo(f"   Batch:        {status['checkpoint']['batch_id']}")
            click.echo(f"   Saved:        {status['checkpoint']['timestamp']}")
        
    except Exception as e:
        click.echo(f"\n‚ùå Status check failed: {e}")
        sys.exit(1)


# =============================================================================
# MAIN ENTRY POINT
# =============================================================================

if __name__ == '__main__':
    cli()
